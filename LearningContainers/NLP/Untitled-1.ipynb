{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Jun/2022 16:54:15] \"\u001b[37mGET /ass HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Jun/2022 16:54:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "Your max_length is set to 130, but you input_length is only 5. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n",
      "127.0.0.1 - - [13/Jun/2022 16:54:26] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Aaaaaaaaa. aaaaaaa. aaaannnnnnnnn. aaaaannn! Aaaaaaannnnnn!'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Jun/2022 16:56:38] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "[2022-06-13 16:56:42,104] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-5-dbb9793afbec>\", line 16, in my_form_post\n",
      "    result = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 235, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 137, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1026, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1033, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 943, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 159, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\", line 1172, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\", line 525, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 798, in forward\n",
      "    embed_pos = self.embed_positions(input_shape)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 137, in forward\n",
      "    return super().forward(positions + self.offset)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 158, in forward\n",
      "    return F.embedding(\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 2183, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n",
      "127.0.0.1 - - [13/Jun/2022 16:56:42] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
      "[2022-06-13 16:56:46,672] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-5-dbb9793afbec>\", line 16, in my_form_post\n",
      "    result = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 235, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 137, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1026, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1033, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 943, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 159, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\", line 1172, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\", line 525, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 798, in forward\n",
      "    embed_pos = self.embed_positions(input_shape)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 137, in forward\n",
      "    return super().forward(positions + self.offset)\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 158, in forward\n",
      "    return F.embedding(\n",
      "  File \"c:\\Users\\junca\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 2183, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n",
      "127.0.0.1 - - [13/Jun/2022 16:56:46] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [13/Jun/2022 16:56:53] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "Your max_length is set to 130, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "127.0.0.1 - - [13/Jun/2022 16:57:01] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'BA.4 and BA.5 are two new subvariants of Omicron that are thought to be more contagious. But they do not appear to lead to more severe disease.'}]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('my-form.html')\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def my_form_post():\n",
    "    text = request.form['text']\n",
    "    #processed_text = text + text\n",
    "    result = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "    print(result)\n",
    "    return jsonify(result=result)\n",
    "\n",
    "\n",
    "@app.route('/test')\n",
    "def hello_name():\n",
    "    return \"processed_text\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "567dc575d908094162af956dd35f0098cfd9569594abc920ea78d4acc651fed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
